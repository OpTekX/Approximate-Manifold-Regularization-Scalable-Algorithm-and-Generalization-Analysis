\relax 
\citation{Argyriou}
\citation{Ciliberto1}
\citation{Ciliberto}
\citation{Evgeniou1}
\citation{Ando}
\citation{Bakker}
\citation{Evgeniou1}
\citation{Evgeniou07}
\citation{Jebara}
\citation{Torralba}
\citation{Yu}
\citation{Zhang05}
\citation{Ando}
\citation{Baxter}
\citation{Ben}
\citation{Minh}
\citation{Greene}
\citation{Allenby}
\citation{Arora}
\citation{Belkin}
\citation{Minh11}
\citation{Minh}
\citation{Brefeld}
\citation{Luo13}
\citation{Luo}
\citation{Minh}
\citation{Rosenberg}
\citation{Sindhwani}
\citation{Sun}
\citation{Micchelli1}
\citation{Micchelli1}
\citation{Bach}
\citation{Bucak}
\citation{Micchelli}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\newlabel{Introduction}{{1}{1}}
\citation{Bach13}
\citation{Rudi}
\citation{Williams}
\citation{Smola}
\citation{Guo17}
\citation{Guo}
\citation{Zhang15}
\citation{Kriukova16}
\citation{Kriukova}
\citation{Kriukova16}
\citation{Micchelli1}
\@writefile{toc}{\contentsline {section}{\numberline {2}Multi-task learning via vector-valued RKHS}{2}}
\citation{Micchelli1}
\newlabel{manifold.funcl}{{1}{3}}
\citation{Minh}
\citation{Kriukova16}
\citation{Smola}
\citation{Williams}
\newlabel{represnter.thm}{{2}{4}}
\newlabel{Nys.approx}{{3}{4}}
\newlabel{multi.plty.funcl1}{{4}{4}}
\citation{Rudi}
\citation{CuckerSmale}
\citation{Cucker}
\newlabel{optimizer}{{2.1}{5}}
\newlabel{fzl}{{2.1}{5}}
\newlabel{fl.funl}{{5}{5}}
\newlabel{fl}{{6}{5}}
\newlabel{fl.funl.sgl}{{7}{5}}
\citation{Devroye}
\citation{Bauer}
\citation{Caponnetto}
\citation{Mathe}
\newlabel{Y.leq.M.1}{{8}{6}}
\newlabel{target.fun}{{9}{6}}
\newlabel{Y.leq.M.2}{{10}{6}}
\newlabel{source.cond}{{2.2}{6}}
\newlabel{poly.decay}{{2.3}{6}}
\citation{Blanchard1}
\citation{Blanchard16}
\citation{Lin}
\citation{Lu16}
\citation{Zhang}
\citation{Caponnetto}
\citation{Kriukova16}
\citation{Rudi}
\citation{Kriukova16}
\citation{Rudi}
\citation{Rudi}
\citation{Kriukova16}
\newlabel{N(l).bound}{{11}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Convergence rates of the regularized learning algorithms based on Nystr{\"o}m subsampling}}{7}}
\newlabel{comparision}{{1}{7}}
\citation{Bauer}
\citation{Caponnetto}
\citation{Pinelis}
\@writefile{toc}{\contentsline {section}{\numberline {3}Convergence issues}{8}}
\newlabel{pinels_lemma}{{3.1}{8}}
\newlabel{pinels_ineq}{{12}{8}}
\newlabel{main.bound}{{3.2}{8}}
\newlabel{LK.I.app}{{13}{8}}
\newlabel{Sx.Sx.LK}{{14}{8}}
\citation{DeVito0}
\citation{Rudi}
\citation{Kriukova16}
\citation{Kriukova16}
\citation{Rudi}
\citation{Mathe2003}
\newlabel{suff_sample}{{15}{9}}
\newlabel{sampling}{{16}{9}}
\newlabel{sampling.para}{{17}{9}}
\newlabel{psi.rates}{{3.1}{10}}
\newlabel{1.bound}{{18}{11}}
\newlabel{2.bound}{{19}{11}}
\newlabel{approx.bound}{{20}{12}}
\newlabel{psi.approx.bound}{{21}{12}}
\newlabel{psi.rates.P1}{{3.2}{12}}
\newlabel{psi.rates.P2}{{3.3}{13}}
\newlabel{fzl.fl.inter}{{22}{13}}
\newlabel{multi.err.upper.bound.p.para.phi}{{3.4}{13}}
\citation{Rastogi}
\citation{Rastogi}
\citation{Anderssen}
\citation{Bauer2}
\citation{JChen}
\citation{Goldenshluger}
\citation{Mathe0}
\citation{Kriukova}
\citation{Kriukova16}
\citation{Pereverzyev}
\citation{Rastogi17}
\newlabel{multi.err.upper.bound.p.para}{{3.5}{14}}
\citation{Kriukova}
\@writefile{toc}{\contentsline {section}{\numberline {4}An aggregation approach for Nystr{\"o}m approximants}{15}}
\newlabel{theoretical.bound}{{4}{15}}
\newlabel{lfs_min}{{23}{15}}
\newlabel{lfs.rates}{{4.1}{15}}
\citation{Minh}
\citation{Minh}
\@writefile{toc}{\contentsline {section}{\numberline {5}Numerical realization}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Caltech-101 data set}{16}}
\newlabel{mv_mls}{{24}{16}}
\newlabel{Laplacian}{{25}{16}}
\citation{Fei}
\citation{Vedaldi}
\citation{Vedaldi}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Semi-supervised least-square regression and classification based on Nystr{\"o}m subsampling using the aggregation approach}}{17}}
\newlabel{Algo.LFS}{{1}{17}}
\citation{Minh}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Performance of multi-view learning estimators based on Nystr{\"o}m subsampling and the aggregated solution based on LFS-$\mathscr  L^2_{\rho _X}$ using $5$ labeled and $5$ unlabeled images per class from Caltech-101 data set.}}{18}}
\newlabel{Table.MVL.5.5}{{2}{18}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Performance of multi-view learning estimators based on Nystr{\"o}m subsampling and the aggregated solution based on LFS-$\mathscr  L^2_{\rho _X}$ using $10$ labeled and $5$ unlabeled images per class from Caltech-101 data set.}}{18}}
\newlabel{Table.MVL.10.5}{{3}{18}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Performance of multi-view learning estimators based on Nystr{\"o}m subsampling and the aggregated solution based on LFS-$\mathscr  L^2_{\rho _X}$ with optimal combination operator using $5$ labeled and $5$ unlabeled images per class from Caltech-101 data set.}}{18}}
\newlabel{Table.MVL.5.5.optC}{{4}{18}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Performance of multi-view learning estimators based on Nystr{\"o}m subsampling and the aggregated solution based on LFS-$\mathscr  L^2_{\rho _X}$ with optimal combination operator using $10$ labeled and $5$ unlabeled images per class from Caltech-101 data set.}}{18}}
\newlabel{Table.MVL.10.5.optC}{{5}{18}}
\newlabel{Kernel}{{26}{18}}
\citation{NSL-KDD}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}NSL-KDD data set}{19}}
\citation{NSL-KDD}
\citation{Alom}
\citation{DeVito}
\citation{Abhishake}
\citation{Farid}
\citation{Alom}
\citation{Onik}
\citation{Abhishake}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Statistical performance of various estimators on different sub-data sets (Folds) of NSL-KDD data set using random subsampling 50 times.}}{21}}
\newlabel{Table.NSL-KDD.rand}{{6}{21}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Statistical performance of various estimators over all 9 sub-data sets (Folds) of NSL-KDD data set.}}{21}}
\newlabel{Table.NSL-KDD.whole}{{7}{21}}
\citation{Onik}
\bibdata{Bib_file}
\bibstyle{plain}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Performance comparison of the proposed model with some existing research work on NSL-KDD data set.}}{22}}
\newlabel{Table.NSL-KDD.comparision}{{8}{22}}
